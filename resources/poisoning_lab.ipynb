{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and data preprocessing\n",
    "\n",
    "#imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import activations\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "import shap\n",
    "\n",
    "# most preprocessing has been done for you but we still need to scale this data\n",
    "df = pd.read_csv(\"numeric.csv\")\n",
    "\n",
    "# scale data with min max\n",
    "scaler = MinMaxScaler()\n",
    "df[df.columns] = scaler.fit_transform(df) #.values\n",
    "\n",
    "# drop truth label from training set, define training and testing sets\n",
    "X = df.drop('label', axis=1)  \n",
    "y = df['label']\n",
    "\n",
    "# define 70/30 ratio for train/test across the lab\n",
    "ratio=0.3\n",
    "\n",
    "# generate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=2023, stratify=y)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "# API calls (features) obtained for graphics\n",
    "features = X_test.columns\n",
    "\n",
    "print(\"This dataset consists of 5816 samples from the EMBER 2018 dataset\")\n",
    "print(\"converted to tabular for ease of use. 2930 of these are malicious,\")\n",
    "print(\"and 2886 are benign. The 17 features are listed below.\\n\\nFeatures:\\n\")\n",
    "for feature in features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a keras neural net. This will be our primary model\n",
    "\n",
    "batchnum=100\n",
    "epochnum=100\n",
    "\n",
    "# define a keras model we can instantiate from this function later\n",
    "def nn_model():\n",
    "    Maldetector = Sequential()\n",
    "    # input layer\n",
    "    Maldetector.add(keras.Input(shape=(17,))) # explicitly define input layer rather than implicit in 1st layer\n",
    "    # hidden layers\n",
    "    Maldetector.add(layers.Dense(128, activation='relu'))\n",
    "    Maldetector.add(layers.Dense(64, activation='relu')) \n",
    "    Maldetector.add(layers.Dense(32, activation='relu'))\n",
    "    Maldetector.add(layers.Dense(32, activation='relu')) # fully connected layer\n",
    "    Maldetector.add(layers.Dense(32, activation='relu')) # fully connected layer\n",
    "    Maldetector.add(layers.Dense(16, activation='relu'))\n",
    "    # output layer\n",
    "    Maldetector.add(layers.Dense(1, activation='sigmoid')) # 1 layer sigmoid for binary classification task\n",
    "    Maldetector.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy', \n",
    "                                                                               tf.keras.metrics.Precision(), \n",
    "                                                                               tf.keras.metrics.Recall()])\n",
    "    return Maldetector\n",
    "\n",
    "# instantiate NN, then fit to training data\n",
    "Maldetector = nn_model()\n",
    "Maldetector.fit(X_train, y_train, epochs=epochnum, batch_size=batchnum, verbose=0)\n",
    "\n",
    "# make some predictions, gather NN metrics\n",
    "mal_loss, mal_acc, mal_precision, mal_recall = Maldetector.evaluate(X_test, y_test, verbose=0)\n",
    "mal_pred = Maldetector.predict(X_test)\n",
    "mal_pred_binary = [1 if pred >= 0.5 else 0 for pred in mal_pred]\n",
    "\n",
    "# calc F1, avoid div by zero\n",
    "try:\n",
    "    mal_f1 = 2 * ((mal_precision * mal_recall) / (mal_precision + mal_recall))\n",
    "except:\n",
    "    mal_f1 = 0.0\n",
    "    print(\"F1 calc error\")\n",
    "\n",
    "# testing loop for NN model\n",
    "acclist = []\n",
    "i=0\n",
    "while(i<10):\n",
    "    Maldetector_loop = nn_model()\n",
    "    Maldetector_loop.fit(X_train, y_train, epochs=epochnum, batch_size=batchnum, verbose=0)\n",
    "    # make some predictions, gather NN metrics\n",
    "    loss, acc, precision, recall = Maldetector_loop.evaluate(X_test, y_test, verbose=0)\n",
    "    acclist.append(round((100 * acc), 2))\n",
    "    i += 1\n",
    "\n",
    "# tabulate results\n",
    "NN_results = PrettyTable([\"Testing Round\", \"Accuracy on Original\"])\n",
    "NN_results.add_row([\"1\", acclist[0]])\n",
    "NN_results.add_row([\"2\", acclist[1]])\n",
    "NN_results.add_row([\"3\", acclist[2]])\n",
    "NN_results.add_row([\"4\", acclist[3]])\n",
    "NN_results.add_row([\"5\", acclist[4]])\n",
    "NN_results.add_row([\"6\", acclist[5]])\n",
    "NN_results.add_row([\"7\", acclist[6]])\n",
    "NN_results.add_row([\"8\", acclist[7]])\n",
    "NN_results.add_row([\"9\", acclist[8]])\n",
    "NN_results.add_row([\"10\", acclist[9]])\n",
    "\n",
    "# results\n",
    "# print Maldetector scores\n",
    "print(\"Model Architecture\")\n",
    "Maldetector.summary()\n",
    "\n",
    "print('\\nKeras Neural Network')\n",
    "print('Accuracy: %.3f' % mal_acc)\n",
    "print('Precision: %.3f' % mal_precision)\n",
    "print('Recall: %.3f' % mal_recall)\n",
    "print('F1 score: %.3f' % mal_f1)\n",
    "\n",
    "# show Maldetector confusion matrix\n",
    "mal_cm = confusion_matrix(y_test, mal_pred_binary)\n",
    "mal_disp = ConfusionMatrixDisplay(confusion_matrix=mal_cm)\n",
    "mal_disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# show loop performance\n",
    "print(\"\\n10 rounds of keras neural networks,\\nmodels trained original data, tested on original data.\")\n",
    "print(NN_results)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a second model, XGBoosted tree, for reference\n",
    "\n",
    "# take the known best model from gridsearch\n",
    "xgb_model = GradientBoostingClassifier(criterion='friedman_mse', loss='exponential', n_estimators=1000)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# make some predictions\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# xgb metrics\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "xgb_precision = precision_score(y_test, xgb_pred)\n",
    "xgb_recall = recall_score(y_test, xgb_pred)\n",
    "xgb_f1 = f1_score(y_test, xgb_pred)\n",
    "\n",
    "# print xgb scores\n",
    "print('\\nXGBoost')\n",
    "print('Accuracy: %.3f' % xgb_acc)\n",
    "print('Precision: %.3f' % xgb_precision)\n",
    "print('Recall: %.3f' % xgb_recall)\n",
    "print('F1 score: %.3f' % xgb_f1)\n",
    "\n",
    "# show XGB confusion matrix\n",
    "xgb_cm = confusion_matrix(y_test, xgb_pred, labels=xgb_model.classes_)\n",
    "xgb_disp = ConfusionMatrixDisplay(confusion_matrix=xgb_cm, display_labels=xgb_model.classes_)\n",
    "xgb_disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a third model, Random Forest Classifier ensemble, for reference\n",
    "\n",
    "# create best model from known gridsearch result\n",
    "rfc_model = RandomForestClassifier(criterion='entropy', n_estimators=400)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "# make some predictions\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "\n",
    "# RFC metrics\n",
    "rfc_acc = accuracy_score(y_test, rfc_pred)\n",
    "rfc_precision = precision_score(y_test, rfc_pred)\n",
    "rfc_recall = recall_score(y_test, rfc_pred)\n",
    "rfc_f1 = f1_score(y_test, rfc_pred)\n",
    "\n",
    "# print RFC scores\n",
    "print('\\nRandom Forest Classifier')\n",
    "print('Accuracy: %.3f' % rfc_acc)\n",
    "print('Precision: %.3f' % rfc_precision)\n",
    "print('Recall: %.3f' % rfc_recall)\n",
    "print('F1 score: %.3f' % rfc_f1)\n",
    "\n",
    "# show RFC confusion matrix\n",
    "rfc_cm = confusion_matrix(y_test, rfc_pred, labels=rfc_model.classes_)\n",
    "rfc_disp = ConfusionMatrixDisplay(confusion_matrix=rfc_cm, display_labels=rfc_model.classes_)\n",
    "rfc_disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabulate results of 3 models trained and tested on regular data\n",
    "\n",
    "multimodel_results = PrettyTable([\"Model\", \"Accuracy on Original Data\"])\n",
    "multimodel_results.add_row([\"Keras Neural Network\", round((100 * mal_acc), 2)])\n",
    "multimodel_results.add_row([\"XGBoost\", round((100 * xgb_acc), 2)])\n",
    "multimodel_results.add_row([\"Random Forest Classifier\", round((100 * rfc_acc), 2)])\n",
    "\n",
    "# show table\n",
    "print(\"\\nA comparison table of models trained and tested on the original dataset\")\n",
    "print(multimodel_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple poisoning attack is label flipping, where we flip the truth label of malicious (1) and benign (0)\n",
    "\n",
    "def flip(row):\n",
    "    if(row['label'] == 1):\n",
    "        return 0\n",
    "    elif(row['label'] == 0):\n",
    "        return 1\n",
    "\n",
    "# generate flipped dataset\n",
    "flip_dataset = df.copy(deep=True)\n",
    "flip_dataset['label'] = flip_dataset.apply(flip, axis=1)\n",
    "\n",
    "# write flip dataset\n",
    "flip_dataset.to_csv('flip.csv', index=False)\n",
    "\n",
    "# drop truth label from training set, define training and testing sets\n",
    "Xf = flip_dataset.drop('label', axis=1)  \n",
    "yf = flip_dataset['label']\n",
    "\n",
    "# train/test split. 70/30 ratio\n",
    "X_trainf, X_testf, y_trainf, y_testf = train_test_split(Xf, yf, test_size=ratio, random_state = 2023, stratify=y)\n",
    "y_trainf = np.array(y_trainf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make each of the models trained on regular data classify on flipped dataset. Notice the difference. \n",
    "# Although simple, this attack is highly effective\n",
    "\n",
    "# NN predictions on flipped set\n",
    "mal_lossf, mal_accf, mal_precisionf, mal_recallf = Maldetector.evaluate(X_testf, y_testf, verbose=0)\n",
    "mal_accf = round((100 *mal_accf), 2)\n",
    "\n",
    "# XGB predictions on flipped set\n",
    "xgb_predf = xgb_model.predict(X_testf)\n",
    "xgb_accf = round((100 * accuracy_score(y_testf, xgb_predf)), 2)\n",
    "\n",
    "# RFC predictions on flipped set\n",
    "rfc_predf = rfc_model.predict(X_testf)\n",
    "rfc_accf = round((100 * accuracy_score(y_testf, rfc_predf)), 2)\n",
    "\n",
    "# tabulate results of 3 models trained and tested on regular data + tested on flipped data\n",
    "multimodelf_results = PrettyTable([\"Model\", \"Accuracy on Original Data\", \"Accuracy on Flipped Data\"])\n",
    "multimodelf_results.add_row([\"Keras Neural Network\", round((100 * mal_acc), 2), mal_accf])\n",
    "multimodelf_results.add_row([\"XGBoost\", round((100 * xgb_acc), 2), xgb_accf])\n",
    "multimodelf_results.add_row([\"Random Forest Classifier\", round((100 * rfc_acc), 2), rfc_accf])\n",
    "\n",
    "# show table\n",
    "print(\"\\nA comparison table of models trained on regular data and tested on the flipped dataset\")\n",
    "print(multimodelf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train one of each model on the flipped dataset, then classify on regular data.\n",
    "# this represents a simple poisoning attack on the training set\n",
    "\n",
    "# NN on flipped data\n",
    "Maldetector_f = nn_model()\n",
    "Maldetector_f.fit(X_trainf, y_trainf, epochs=epochnum, batch_size=batchnum, verbose=0) # train on flipped\n",
    "mal_lossf, mal_accf, mal_precisionf, mal_recallf = Maldetector_f.evaluate(X_test, y_test, verbose=0) # predict on original\n",
    "\n",
    "# XGB on flipped data\n",
    "xgb_model_f = GradientBoostingClassifier(criterion='friedman_mse', loss='exponential', n_estimators=1000)\n",
    "xgb_model_f.fit(X_trainf, y_trainf) # train on flipped\n",
    "xgb_predf = xgb_model_f.predict(X_test) # predict on original\n",
    "xgb_accf = accuracy_score(y_test, xgb_predf)\n",
    "\n",
    "# RFC on flipped data\n",
    "rfc_model_f = RandomForestClassifier(criterion='entropy', n_estimators=400)\n",
    "rfc_model_f.fit(X_trainf, y_trainf) # train on flipped\n",
    "rfc_predf = rfc_model_f.predict(X_test) # predict on original\n",
    "rfc_accf = accuracy_score(y_test, rfc_predf)\n",
    "\n",
    "# tabulate results of 3 models trained on flipped data, tested on regular data\n",
    "flip_results = PrettyTable([\"Model\", \"Accuracy on Original Data\"])\n",
    "flip_results.add_row([\"Keras Neural Network\", round((100 * mal_accf), 2)])\n",
    "flip_results.add_row([\"XGBoost\", round((100 * xgb_accf), 2)])\n",
    "flip_results.add_row([\"Random Forest Classifier\", round((100 * rfc_accf), 2)])\n",
    "\n",
    "# show table\n",
    "print(\"\\nA comparison table of models trained on flipped data and tested on the original dataset.\")\n",
    "print(\"This is a simple demonstration of poisoning the training dataset, yet it is highly effective.\")\n",
    "print(flip_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we explore a more nuanced poisoning attack with additive perturbations targeting specific features, informed by SHAP.\n",
    "\n",
    "# Keras Neural Net explanation using SHapely Additive exPlanations (SHAP). This is the original trained model.\n",
    "\n",
    "# set up js for rendering SHAP graphics\n",
    "shap.initjs()\n",
    "\n",
    "# SHAP is a heavy calculation that takes time. This sample makes this job take less time, but renders the interpretation less\n",
    "# accurate the smaller the sample gets.\n",
    "sample = shap.sample(X_test, 100)\n",
    "\n",
    "# generate explanation of the NN trained on the normal dataset using SHAP\n",
    "mal_explainer = shap.KernelExplainer(Maldetector, sample)\n",
    "mal_shap_values = mal_explainer.shap_values(sample)\n",
    "shap.summary_plot(mal_shap_values, features, class_names=[\"Benign\", \"Malicious\"], max_display=17, plot_type=\"bar\", plot_size=\"auto\", show=True)\n",
    "\n",
    "# scroll to the bottom of this cell to view the rendered plot. Take note of the top 3 features the model bases its \n",
    "# predictions on. These will be the targets of our poisoning attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to derive boundaries for our attack by statistically analyzing the dataset\n",
    "# derive the mean value (average) for each class, separated by malicious and benign\n",
    "# this way we can see the general differences between the malicious and benign classes\n",
    "\n",
    "# calculate averages to use as bounds in perturbing the datset\n",
    "# for each feature column in df, split dataframe into 2: \n",
    "# 1 malicious df and 1 benign df. These are copies of the scaled data\n",
    "\n",
    "# drop benign, leaving malicious\n",
    "malicious = df.copy(deep=True)\n",
    "malicious.drop(malicious[malicious.label==0].index, inplace=True)\n",
    "malicious.drop('label', axis=1, inplace=True) # truth label excluded. Its attack already demonstrated in label flipping\n",
    "malicious.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# drop malicious, leaving benign\n",
    "benign = df.copy(deep=True)\n",
    "benign.drop(benign[benign.label==1].index, inplace=True)\n",
    "benign.drop('label', axis=1, inplace=True)\n",
    "benign.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# average of malicious for each column\n",
    "malcol_avgs = malicious.mean()\n",
    "\n",
    "# average of benign for each column\n",
    "bencol_avgs = benign.mean()\n",
    "\n",
    "# print all the resultant data in a pretty table\n",
    "averages = PrettyTable([\"Feature\", \"Benign Averages\", \"Malicious Averages\"])\n",
    "averages.add_row([\"avlength\", bencol_avgs.at['avlength'], malcol_avgs.at['avlength']])\n",
    "averages.add_row([\"coff.timestamp\", bencol_avgs.at['coff.timestamp'], malcol_avgs.at['coff.timestamp']])\n",
    "averages.add_row([\"entropy\", bencol_avgs.at['entropy'], malcol_avgs.at['entropy']])\n",
    "averages.add_row([\"exports_counts\", bencol_avgs.at['exports_counts'], malcol_avgs.at['exports_counts']])\n",
    "averages.add_row([\"has_debug\", bencol_avgs.at['has_debug'], malcol_avgs.at['has_debug']])\n",
    "averages.add_row([\"has_relocations\", bencol_avgs.at['has_relocations'], malcol_avgs.at['has_relocations']])\n",
    "averages.add_row([\"has_resources\", bencol_avgs.at['has_resources'], malcol_avgs.at['has_resources']])\n",
    "averages.add_row([\"has_signature\", bencol_avgs.at['has_signature'], malcol_avgs.at['has_signature']])\n",
    "averages.add_row([\"imports_counts\", bencol_avgs.at['imports_counts'], malcol_avgs.at['imports_counts']])\n",
    "averages.add_row([\"MZ\", bencol_avgs.at['MZ'], malcol_avgs.at['MZ']])\n",
    "averages.add_row([\"numstrings\", bencol_avgs.at['numstrings'], malcol_avgs.at['numstrings']])\n",
    "averages.add_row([\"paths\", bencol_avgs.at['paths'], malcol_avgs.at['paths']])\n",
    "averages.add_row([\"printables\", bencol_avgs.at['printables'], malcol_avgs.at['printables']])\n",
    "averages.add_row([\"registry\", bencol_avgs.at['registry'], malcol_avgs.at['registry']])\n",
    "averages.add_row([\"size\", bencol_avgs.at['size'], malcol_avgs.at['size']])\n",
    "averages.add_row([\"urls\", bencol_avgs.at['urls'], malcol_avgs.at['urls']])\n",
    "averages.add_row([\"vsize\", bencol_avgs.at['vsize'], malcol_avgs.at['vsize']])\n",
    "\n",
    "print(\"\\nAverages of scaled dataset by feature, separated by malicious and benign samples.\")\n",
    "print(\"These will inform target values to push data towards in our perturbations.\\n\")\n",
    "print(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the features of interest from SHAP explanation and the boundaries we derive from our statistical analysis, \n",
    "# perturb the dataset to generate a poisoned training set\n",
    "\n",
    "# perturb function takes col (feature name), bavg (benign average for that feature),\n",
    "# mavg (malicious average for that feature), and a small decimal factor to control the size of the perturbation\n",
    "def perturb(row, col, bavg, mavg, factor):\n",
    "    if(row['label'] == 1):\n",
    "        # if current row malware, push from above or below to bavg by a factor of itself to make look more like benign\n",
    "        if(row[col] > bavg):\n",
    "            return abs((row[col] - (row[col] * factor)))\n",
    "        elif(row[col] < bavg):\n",
    "            return abs((row[col] + (row[col] * factor)))\n",
    "    elif(row['label'] == 0):\n",
    "        # if current row benign, push from above or below to mavg by a factor of itself to make look more like malicious\n",
    "        if(row[col] > mavg):\n",
    "            return abs((row[col] - (row[col] * factor)))\n",
    "        elif(row[col] < mavg):\n",
    "            return abs((row[col] + (row[col] * factor)))\n",
    "\n",
    "poison_dataset = df.copy(deep=True)\n",
    "factor = 0.1 # .5 brings down to 60% acc. 0.05 brings down to 81-72 acc\n",
    "\n",
    "# =================================== your work here ============================================================\n",
    "# CHANGE THIS:\n",
    "# Given the three features discovered from the SHAP explanation, and the corresponding averages for malicious and \n",
    "# benign samples over those features, create a poisoned dataset here targeting those features. Call perturb 3 times\n",
    "# to poison your 3 target features.\n",
    "\n",
    "# args are feature, benign sample average over feature, malicious sample average over feature, factor to perturb by.\n",
    "# Change the column index of the feature you want to change as well. Examples commented below.\n",
    "\n",
    "# poison_dataset['featureName'] = poison_dataset.apply(perturb, axis=1, args=('featureName', benign_avg, mal_avg, factor))\n",
    "#poison_dataset['entropy'] = poison_dataset.apply(perturb, axis=1, args=('entropy', 0.8625272385686976, 0.902868372786425, factor))\n",
    "#poison_dataset['has_relocations'] = poison_dataset.apply(perturb, axis=1, args=('has_relocations', 0.6036036036036037, 0.4768305624336753, factor))\n",
    "#poison_dataset['coff.timestamp'] = poison_dataset.apply(perturb, axis=1, args=('coff.timestamp', 0.2915475344330408, 0.30322718417659084, factor))\n",
    "\n",
    "\n",
    "# ================================================================================================================\n",
    "\n",
    "# write poison dataset\n",
    "poison_dataset.to_csv('poison.csv', index=False)\n",
    "\n",
    "# drop truth label from training set, define training and testing sets\n",
    "Xp = poison_dataset.drop('label', axis=1)  \n",
    "yp = poison_dataset['label']\n",
    "\n",
    "# train/test split. 80/20 ratio\n",
    "X_trainp, X_testp, y_trainp, y_testp = train_test_split(Xp, yp, test_size=0.2, random_state = 2023, stratify=y)\n",
    "y_trainp = np.array(y_trainp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with our newly poisoned dataset, train a new neural network on this poisoned data and predict on regular data. This is \n",
    "# a SHAP-informed poisoning attack against the training set targeting specific features of interest\n",
    "\n",
    "acclistp = []\n",
    "i=0\n",
    "while(i<10):\n",
    "    Maldetector_p = nn_model()\n",
    "    Maldetector_p.fit(X_trainp, y_trainp, epochs=epochnum, batch_size=batchnum, verbose=0) # train on poison\n",
    "    lossp, accp, precisionp, recallp = Maldetector_p.evaluate(X_test, y_test, verbose=0) # test on original data\n",
    "    acclistp.append(round((100 * accp), 2))\n",
    "    i += 1\n",
    "\n",
    "Maldetector_p = nn_model()\n",
    "Maldetector_p.fit(X_trainp, y_trainp, epochs=epochnum, batch_size=batchnum, verbose=0) # train on poison\n",
    "mal_lossp, mal_accp, mal_precisionp, mal_recallp = Maldetector_p.evaluate(X_test, y_test, verbose=0) # predict on original\n",
    "\n",
    "# tabulate results\n",
    "NNp_results = PrettyTable([\"Testing Round\", \"NN Trained on Original\", \"NN Trained on Poison\"])\n",
    "NNp_results.add_row([\"1\", acclist[0], acclistp[0]])\n",
    "NNp_results.add_row([\"2\", acclist[1], acclistp[1]])\n",
    "NNp_results.add_row([\"3\", acclist[2], acclistp[2]])\n",
    "NNp_results.add_row([\"4\", acclist[3], acclistp[3]])\n",
    "NNp_results.add_row([\"5\", acclist[4], acclistp[4]])\n",
    "NNp_results.add_row([\"6\", acclist[5], acclistp[5]])\n",
    "NNp_results.add_row([\"7\", acclist[6], acclistp[6]])\n",
    "NNp_results.add_row([\"8\", acclist[7], acclistp[7]])\n",
    "NNp_results.add_row([\"9\", acclist[8], acclistp[8]])\n",
    "NNp_results.add_row([\"10\", acclist[9], acclistp[9]])\n",
    "\n",
    "# show loop performance\n",
    "print(\"\\n10 rounds of Keras Neural Networks.\")\n",
    "print(\"One trained on original data, one trained on poison.\\nBoth tested on original dataset.\")\n",
    "print(NNp_results)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also explain our other two models to see which features are most important to their predictions. From this, \n",
    "# we can speculate on whether the poisoned dataset for the neural network will also be transferrable to the \n",
    "# XGBoosted model and Random Forest ensemble\n",
    "\n",
    "# SHAP explanation of XGBoost trained on original data\n",
    "print(\"XGB Summary Plot\")\n",
    "xgb_explainer = shap.TreeExplainer(xgb_model)\n",
    "xgb_shap_values = xgb_explainer.shap_values(X_test)\n",
    "shap.summary_plot(xgb_shap_values, features, class_names=[\"Benign\", \"Malicious\"], max_display=17, plot_type=\"bar\", plot_size=\"auto\", show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP explanation of RFC trained on original dataset\n",
    "print(\"RFC Summary Plot\")\n",
    "rfc_explainer = shap.TreeExplainer(rfc_model)\n",
    "rfc_shap_values = rfc_explainer.shap_values(X_test)\n",
    "shap.summary_plot(rfc_shap_values, features, class_names=[\"Benign\", \"Malicious\"], max_display=17, plot_type=\"bar\", plot_size=\"auto\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test transferability of poison targeting NN against all models\n",
    "\n",
    "# XGB on poison data\n",
    "xgb_model_p = GradientBoostingClassifier(criterion='friedman_mse', loss='exponential', n_estimators=1000)\n",
    "xgb_model_p.fit(X_trainp, y_trainp) # train on poison\n",
    "xgb_predp = xgb_model_p.predict(X_test) # predict on original\n",
    "xgb_accp = accuracy_score(y_test, xgb_predp)\n",
    "\n",
    "# RFC on poison data\n",
    "rfc_model_p = RandomForestClassifier(criterion='entropy', n_estimators=400)\n",
    "rfc_model_p.fit(X_trainp, y_trainp) # train on poison\n",
    "rfc_predp = rfc_model_p.predict(X_test) # predict on original\n",
    "rfc_accp = accuracy_score(y_test, rfc_predp)\n",
    "\n",
    "# big table with each model type trained on poison, trained on regular, all tested on regular\n",
    "# this will be the transferability of perturbations table\n",
    "\n",
    "# tabulate results\n",
    "transfer_results = PrettyTable([\"Model\", \"Trained on Original\", \"Trained on Poison\"])\n",
    "transfer_results.add_row([\"Keras Neural Network\", round((100 * mal_acc), 2), round((100 * mal_accp), 2)])\n",
    "transfer_results.add_row([\"XGBoost\", round((100 * xgb_acc), 2), round((100 * xgb_accp), 2)])\n",
    "transfer_results.add_row([\"Random Forest Classifier\", round((100 * rfc_acc), 2), round((100 * rfc_accp), 2)])\n",
    "\n",
    "# show transferability performance\n",
    "print(\"\\nTable demonstrating transferability of perturbations across models.\")\n",
    "print(\"One trained on original data, one trained on poison.\\nAll tested on original dataset.\")\n",
    "print(transfer_results)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
